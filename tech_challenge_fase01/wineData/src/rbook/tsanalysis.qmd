---
code-fold: true
editor: 
  markdown: 
    wrap: sentence
tbl-cap-location: bottom
---

```{css, echo = FALSE}
.justify {
  text-align: justify !important
}
```

```{r import_libs}
#| echo: false
#| message: false
#| warning: false

source('utils.R')

```
# Análise das séries temporais agregadas


::: {style="text-align: justify"}

Para analisar o comportamento das séries temporais, o ideal é poder contar com o maior número de dados possível. Neste caso, é razoável optarmos por analisar as séries mensais ao invés das séries anuais. Inclusive, com as séries mensais é possível realizarmos a análise de curto-prazo e médio-prazo.

Inicialmente iremos avaliar o comportamento das séries em termos agregados (soma de todos os países) para buscarmos _insights_ sobre o mercado como um todo. Posteriormente, realizaremos a análise considerando somente os 2 maiores importadores de vinhos brasileiros: Paraguai e Rússia.
:::

## Análise das séries agregadas

::: {style="text-align: justify"}
```{r}
#| echo: false
#| warning: true
#| message: false

load('data_exp_mc.RData')

# agregação dos dados mensais por data
data_exp_mc_by_date <- data_exp_mc  |> 
                        group_by(date) |> 
                        dplyr::summarise(sum_val = sum(value), 
                                  sum_vol = sum(volume),
                                  # mean_val = mean(value),
                                  # mean_vol = mean(volume),
                                  ) |> 
                        dplyr::arrange(desc(date))


```

As séries de valor exportado mensal total permite identificar vales e picos como em março de 2009 e julho de 2013 (@fig-monthly_val_agg).

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-monthly_val_agg
#| fig-cap: 'Valor total exportado mensal (US\$)'

data_exp_mc_by_date |> timetk::plot_time_series(date, sum_val, 
                                                .interactive = T, 
                                                .smooth_span = 0.15,
                                 .title = 'Valor total')

# data_exp_mc_by_date |> timetk::plot_time_series(date, mean_val, .interactive = T, 
#                                                 .smooth_span = 0.15, .line_color = "red",
#                                  .title = 'Valor médio')

```
Igualmente, nos gráficos da @fig-monthly_vol_agg em julho de 2009 e abril de 2013.


```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-monthly_vol_agg
#| fig-cap: 'Volume total mensal (Kg.L)'

data_exp_mc_by_date |> timetk::plot_time_series(date, sum_vol, 
                                                .interactive = T, 
                                                .smooth_span =  0.15,
                                 .title = 'Volume total')

# data_exp_mc_by_date |> timetk::plot_time_series(date, mean_vol, 
#                                                 .interactive = T, 
#                                                 .line_color = "red",
#                                                 .smooth_span = 0.15,
#                                  .title = 'Volume médio')

```
Porém, para realizar uma análise mais apurada, inclusive identificando de modo sistemático eventos anômalos, podemos utilizar algorítmos de identificação de anomalias, como será exposto a seguir.

:::

### Detecção de anomalias

::: {style="text-align: justify"}


O primeiro passo para a detecção de anomalias é a decomposição da série em suas componentes de tendência e sazonalidade, além de podermos também verificar os resíduos das séries. 

Os gráficos da @fig-monthly_decomp_val mostra que existe um forte componente sazonal atuando e a tendência é crescente.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-monthly_decomp_val
#| fig-cap: 'Decomposição da série de valor total'

anomalize_sum_val <-  data_exp_mc_by_date |>  
                                          timetk::anomalize(
                                              .date_var      = date, 
                                              .value         = sum_val,
                                              .iqr_alpha     = 0.05,
                                              .max_anomalies = 0.20,
                                              .message       = FALSE
                                          )
        
# anomalize_mean_val <-  data_exp_mc_by_date |>  
#                                           timetk::anomalize(
#                                               .date_var      = date, 
#                                               .value         = mean_val,
#                                               .iqr_alpha     = 0.05,
#                                               .max_anomalies = 0.20,
#                                               .message       = FALSE
#                                           )
#         
anomalize_sum_val |> timetk::plot_anomalies_decomp(.date_var = date,
                                                   .interactive = TRUE,
                                                   .title = "Valor total")

# anomalize_mean_val |> timetk::plot_anomalies_decomp(.date_var = date, 
#                                                     .interactive = TRUE,
#                                                     .title = "Valor médio")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-monthly_decomp_vol
#| fig-cap: 'Decomposição da série de volume total'

anomalize_sum_vol <-  data_exp_mc_by_date |>  
                                          timetk::anomalize(
                                              .date_var      = date, 
                                              .value         = sum_vol,
                                              .iqr_alpha     = 0.05,
                                              .max_anomalies = 0.20,
                                              .message       = FALSE
                                          )
        
# anomalize_mean_vol <-  data_exp_mc_by_date |>  
#                                           timetk::anomalize(
#                                               .date_var      = date, 
#                                               .value         = mean_vol,
#                                               .iqr_alpha     = 0.05,
#                                               .max_anomalies = 0.20,
#                                               .message       = FALSE
#                                           )
        
anomalize_sum_vol |> timetk::plot_anomalies_decomp(.date_var = date, 
                                                   .interactive = TRUE, 
                                                   .title = "Volume total")

# anomalize_mean_vol |> timetk::plot_anomalies_decomp(.date_var = date, 
#                                                     .interactive = TRUE,
#                                                     .title = "Valor médio")
```


Os gráficos da @fig-monthly_anomalize_plot-1 e @fig-monthly_anomalize_plot-2 permitem identicar as anomalias das séries. Enquanto na série de valors total foram identificadas 8 anomalias. Já na série de volume total from identificadas 25. Coincidem entre as séries as anomalias identificadas em dois meses de 2009, um em 2012 e três em 2013 (@tbl-monthly_anomalize_summary). 
:::{#tbl-monthly_anomalize_summary}
```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-monthly_anomalize_summary
#| tbl-cap: "Principais dados sobre as anomalias identificadas" 

dt_val <- anomalize_sum_val |> filter(anomaly == "Yes") |> select(date) 
dt_vol <- anomalize_sum_vol |> filter(anomaly == "Yes") |> select(date) 


DT::datatable(merge(dt_val, dt_vol), 
                          filter = "bottom", 
                          colnames = 'Data',
                          extensions = 'Buttons', 
                          options = list(
                          dom = 'Bfrtip',
                          buttons = c('copy','excel', 'csv', 'pdf'))) |>  DT::formatDate(columns = c('date'),
                               'toLocaleDateString')
    
```
:::

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-monthly_anomalize_plot
#| fig-cap: 
#| - 'Detecção de anomalias - valor total'
#| - 'Detecção de anomalias - volume total'
#| layout-nrow: 2 


anomalize_sum_val |> timetk::plot_anomalies(.date_var = date, 
                                            .interactive = TRUE, 
                                            .title = "Valor total")


anomalize_sum_vol |> timetk::plot_anomalies(.date_var = date, 
                                            .interactive = TRUE, 
                                            .title = "Volume total")

```

Para série da valor as anomalias ocorrem entre junho de 2009 e setembro de 2017. Já para série de volume exportado, as anomalias ocorrem entre setembro de 2008 e agosto de 2013.

Detectar as anomalias pode ser bastante útil para tentar relacioná-las a eventos externos e verificar se há algum tipo de relação entre eles e o comportamento da série temporal.

:::

### Funções de autocorrelação (ACF) e autorrelação parcial (PACF)

::: {style="text-align: justify"}

A função de autocorrelação (ACF) e a função de autocorrelação parcial (PACF) são medidas de associação entre valores autais e valores pregressos em séries temporais[^exploratory_yearly-1]. Portanto, indicam em que medida um valor $x_t$ é dependente do valor $x_{t-1}$ e, consequentemente, o passado é últil para prever o futuro.

A autocorrelação parcial é mais útil durante o processo de especificação de um modelo autoregressivo. Ela ajuda a avaliar as propriedades de uma série temporal.

As funções de autocorrelação e autocorrelação parcial também servem para estudar a estacionariedade de uma série temporal[^exploratory_yearly-2].Uma série temporal estacionária tem funções de média, variância e autocorrelação que são essencialmente constantes ao longo do tempo[^exploratory_yearly-3]. A função de autocorrelação diminui para quase zero rapidamente para uma série temporal estacionária (decaimento exponencial).

Os modelos matemáticos mais comuns e que têm como premissa apresentar a estacionariedade são modelos auto-regressivos - AR (p), auto-regressivo e de média móvel - ARMA (p,q) - e modelo auto—regressivo integrado e de média móvel - ARIMA(p,d,q)[^exploratory_yearly-4].

Para uma série temporal estacionária, um modelo de média móvel vê o valor de uma variável no tempo $t$ como uma função linear de erros residuais de $q$ defasagens. Já um processo auto-regressivo de ordem $p$ é um modelo que utiliza os próprios valores passados como preditores[^exploratory_yearly-5]. O termo $d$ especifica a ordem de integração da série (ou seja, quantas vezes a série deve ser diferenciada para se tornar estacionária).

As ordens dos processos em termos de $p$ e $q$ são definidas com base na análise das funções de autocorrelação e autocorrelação parcial. A ordem $p$ do processo auto-regressivo é determinada pela função de autocorrelação parcial, enquanto a ordem $q$ do processo de média móvel é indicada pelo número de correlações estatisticamente significativas na função de autocorrelação[^exploratory_yearly-6].

Estabelecidos os conceitos e aplicações da ACF e da PACF, passemos à análise das séries de interesse.

Primeiramente, utilizaremos a série sem as anomalias detectadas na seção anterior, pois assim os valores anômalos não irão interferir na modelagem. A @tbl-data_exp_mc_clean, a @fig-data_exp_mc_clean-1 e a @fig-data_exp_mc_clean-2 mostram o conjunto de dados contendo as séries originais e aquelas resultantes da exclusão das anomalias.

:::

### Séries sem as anomalias detectadas

::: {style="text-align: justify"}

::: {#tbl-data_exp_mc_clean}
```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-data_exp_mc_clean


data_exp_mc_by_date_clean <- data_exp_mc_by_date |>
  left_join(anomalize_sum_val, join_by(date)) |>
  select(c(date, sum_val, sum_vol, observed_clean)) |>
  rename(sum_val_clean = observed_clean) |>
  left_join(anomalize_sum_vol, join_by(date)) |>
  select(c(date, sum_val, sum_vol, sum_val_clean, observed_clean)) |>
  rename(sum_vol_clean = observed_clean)

DT::datatable(
  data_exp_mc_by_date_clean,
  filter = "bottom",
  colnames = c(
    'Data',
    'Valor total',
    'Volume total',
    'Valor total sem anomalias',
    'Volume total sem anomalias'
  ),
  extensions = 'Buttons',
  options = list(
    dom = 'Bfrtip',
    buttons = c('copy', 'excel', 'csv', 'pdf')
  )
) |>
  DT::formatDate(columns = c('date'),
                 'toLocaleDateString') |>
  DT::formatCurrency(
    columns = c('sum_val', 'sum_val_clean'),
    currency = '$',
    dec.mark = ',',
    mark = '.'
  ) |>
  DT::formatRound(
    columns = c("sum_vol", "sum_vol_clean"),
    digits = 2,
    dec.mark = ",", mark = "."
  )

```
Dados originais e sem anomalias.
:::

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-data_exp_mc_clean
#| layout-nrow: 2
#| fig-cap: 
#| - "Valor total exportado - dados originais e dados sem anomalias"
#| - "Volume total exportado - dados originais e dados sem anomalias"



ggplotly(
  data_exp_mc_by_date_clean |> ggplot(aes(x = date, y = sum_val)) +
    geom_line(colour = "red") +
    geom_line(aes(x = date, y = sum_val_clean), colour = "blue", alpha = 0.80) +
    theme_minimal() +
    theme(axis.text.x = element_text(
      angle = 90,
      vjust = 1,
      hjust = 1
    )) +
    labs(
      title = "Valor total exportado - dados originais e dados sem anomalias",
      x = "Data",
      y = "US$",
    ) + scale_y_continuous(labels = scales::dollar)
)

ggplotly(
  data_exp_mc_by_date_clean |> ggplot(aes(x = date, y = sum_vol)) +
    geom_line(colour = "red") +
    geom_line(aes(x = date, y = sum_vol_clean), colour = "blue", alpha = 0.80) +
    theme_minimal() +
    theme(axis.text.x = element_text(
      angle = 90,
      vjust = 1,
      hjust = 1
    )) +
    labs(
      title = "Volume total exportado - dados originais e dados sem anomalias",
      x = "Data",
      y = "Kg.L",
    ) + scale_y_continuous(labels = scales::label_number(big.mark = "."))
)

```
:::

### Decomposição sazonal

::: {style="text-align: justify"}

```{r}
#| echo: false
#| message: false
#| warning: false
#| layout-nrow: 2 
#| label: fig-data_exp_mc_clean_acf_pacf
#| fig-cap: 'Valor exportado mensal (US\$) - ACF e PACF.'
#| fig-subcap: 
#| - "Valor total"
#| - "Valor médio"

data_exp_mc_by_date_clean |> timetk::plot_stl_diagnostics(date, sum_val_clean, .interactive = T, 
                                                    .title = 'Valor total exportado - ACF e PACF.')

data_exp_mc_by_date_clean |> timetk::plot_stl_diagnostics(date, sum_vol_clean, .interactive = T, 
                                                    .title = 'Volume total exportado - ACF e PACF.')

```

Claramente a @fig-data_exp_mc_clean-1 e @fig-data_exp_mc_clean-2 demonstram que a remoção das anomalias contribui para a suavização da tendência das séries, o que diminui a possibilidade de existir uma raiz unitária e, consequentemente, a série ser não-estacionária. 

:::

### Funções de autocorrelação e autocorrelação parcial

::: {style="text-align: justify"}

Para a série de *valor exportado* temos os gráficos da @fig-data_exp_mc_clean_acf_pacf-1 e @fig-data_exp_mc_clean_acf_pacf-2 de ACF e PACF, considerando 48 defasagens.

```{r}
#| echo: false
#| message: false
#| warning: false
#| layout-nrow: 2 
#| label: fig-acf_pacf_total
#| fig-cap: 'Valor exportado mensal (US\$) - ACF e PACF.'
#| fig-subcap: 
#| - "Valor total"
#| - "Valor médio"

data_exp_mc_by_date |> timetk::plot_acf_diagnostics(date, sum_val, .interactive = T, .lags = 0:48,
                                                    .title = 'Valor total exportado - ACF e PACF.')

data_exp_mc_by_date |> timetk::plot_acf_diagnostics(date, sum_vol, .interactive = T, .lags = 0:48,
                                                    .title = 'Volume total exportado - ACF e PACF.')

```

Nos gráficos acima, as decomposições mostram que existem autocorrelação e autocorrelação parcial estatisticamente significativas. Mais precisamente, em ambas as séries, a ACF decai de modo suave enquanto que a PACF decai de modo mais abrupto. Tal padrão sugere que ambas as funções podem ser modeladas por meio de um processo do tipo $ARMA(p,q)$[^exploratory_yearly-7].

Porém, a inspeção visual é bastante limitada, o que nos motiva a aprofundar a análise.
:::
    
[^exploratory_yearly-1]: https://www.ibm.com/docs/pt-br/spss-modeler/18.4.0?topic=data-autocorrelation-partial-autocorrelation-functions

[^exploratory_yearly-2]: https://ichi.pro/pt/autocorrelacao-e-autocorrelacao-parcial-em-dados-de-serie-temporal-32975526028430

[^exploratory_yearly-3]: https://analisemacro.com.br/estatistica-e-econometria/estacionariedade-de-series-temporais/

[^exploratory_yearly-4]: https://medium.com/data-hackers/series-temporais-parte-1-a0e75a512e72

[^exploratory_yearly-5]: https://tutoriais.edu.lat/pub/time-series/time-series-moving-average/serie-temporal-media-movel

[^exploratory_yearly-6]: https://support.minitab.com/pt-br/minitab/20/help-and-how-to/statistical-modeling/time-series/how-to/autocorrelation/interpret-the-results/autocorrelation-function-acf/

[^exploratory_yearly-7]: da Silveira Bueno, Rodrigo de Losso.Econometria De Séries Temporais. Cengage Learning; 2ª Edição Revista E Atualizada (28 julho 2011),pp.47.

[^exploratory_yearly-8]: da Silveira Bueno, Rodrigo de Losso.Econometria De Séries Temporais.Cengage Learning; 2ª Edição Revista E Atualizada (28 julho 2011),pp.47.

    
### Teste de raiz unitária, quebras estruturais e modelos de previsão

::: {style="text-align: justify"}
Como ressaltamos na seção anterior, a estacionariedade é uma propriedade importante na análise de séries temporais.
Um grande número de modelos assumem a estacionariedade do processo (como os modelos ARMA e ARIMA) e, além disso,um modelo de série temporal que não é estacionário irá variar a sua acurácia à medida que as métricas da série de tempo variarem[^exploratory_yearly-9].

Assim, na análise de séries temporais é possível se utilizar de estratégias como a transformação logarítimica, a transformação quadrática ou ainda a diferenciação. Vale dizer que as duas primeiras buscam atacar a alteração da variância no tempo, enquanto que a última foca na remoção da tendência.

Nas séries em questão, verificar se existe raiz unitária e, portanto, é necessário aplicar algum tipo de transformação para modelar a série.

:::
    
[^exploratory_yearly-9]: Nielsen, Aileen.Practical Time Series Analysis: Prediction with Statistics and Machine Learning.O'Reilly Media; 1ª edição (19 novembro 2019).pp.85

[^exploratory_yearly-10]: Nielsen, Aileen.Practical Time Series Analysis: Prediction with Statistics and Machine Learning.O'Reilly Media; 1ª edição (19 novembro 2019).pp.85

    
#### Testes de raiz unitária
    
::: {style="text-align: justify"}

Para identificar a existência de raiz unitária, isto é, não estacionariedade, os testes que utilizaremos são: - Augmented Dickey-Fuller (ADF) - Hipótese nula ($H_0$): a série **possui** uma raiz unitária, logo não é estacionária[^exploratory_yearly-11]; - Kwiatkowski–Phillips–Schmidt–Shin (KPSS) - Hipótese nula ($H_0$): a série **não possui** uma raiz unitária, logo é estacionária[^exploratory_yearly-12].

Primeiro aplicaremos os testes às séries em nível e, caso seja necessário, posteriormente à séries em $log$. Se a série em nível for estacionária, não será necessária a transformação. Eventual transformação necessariamente implica em perda de informação (o $log$ reduz a diferença entre extremos, o que pode afetar a compreensão do fenômeno objeto de análise).

O resultado a seguir se referece à aplicação dos testes ADF e KPSS à série de valor exportado, considerando um modelo com tendência considerando o observado em @fig-monthly_decomp_val e @fig-monthly_decomp_vol.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: unit_root_val
ts <- ts(data_exp_mc_by_date_clean |> 
             select(sum_val_clean),
         frequency = 12, 
         start = c(2000,01,01), 
         end = c(2022,01,12)
)

ur_test(ts, type_adf = "trend", type_kpss = "tau")
```

No teste ADF o p-valor mostra que a hipótese $H_0$ **pode ser rejeitada** considerando 5% de nível de significância - 0,01 \< 0,05 e o módulo das estatísticas $\tau_3$, $\phi_2$ e $\phi_3$ é maior que o módulo dos valores críticos.
No teste KPSS o resultado indica que a hipótese $H_0$ **pode ser rejeitada** a 5% de significância, visto que 0,089 \< 0,146.
Os resultados dos testes são contraditórios e, em princípio poderíamos dizer que a série é estácionária em primeira diferença, ou seja, . Por outro lado, a rejeição da hipótese nula no KPSS se deu por uma pequena diferença em relação ao valor crítico. Mais adiante poderemos nos certificar de que a série não possui raiz unitária.

Abaixo está o resultado dos testes de raiz unitária para a série de volume exportado.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: unit_root_vol


ts <- ts(data_exp_mc_by_date_clean |> 
             select(sum_vol_clean),
         frequency = 12, 
         start = c(2000), 
         end = c(2022)
)

ur_test(ts, type_adf = "drift", type_kpss = "mu")
```

No teste ADF o p-valor mostra que a hipótese $H_0$ **pode ser rejeitada** considerando 5% de nível de significância, pois 0,01 \< 0,05 e o módulo das estatísticas $\tau_2$ e $\phi_1$ é maior que o módulo dos valores críticos.
No teste KPSS o resultado indica que a hipótese $H_0$ **não pode ser rejeitada** a 5% de significância, visto que 0,203 \< 0,463.
Neste sentido, a série não possui raiz unitária.

:::
    
[^exploratory_yearly-11]: https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test

[^exploratory_yearly-12]: https://en.wikipedia.org/wiki/KPSS_test

### Testes de quebra estrutural

::: {style="text-align: justify"}

A existência de quebras estruturais^[https://en.wikipedia.org/wiki/Structural_break#:~:text=Structural%20break%20tests,-A%20single%20break&text=For%20linear%20regression%20models%2C%20the,...%2CT%5D.] nas séries temporais além de serem eventual causa de existência de raiz unitária, também podem auxiliar a compreensão do fenômeno analisado, vez que indicam a existência, por exemplo, de alterações na tendência da série e, deste modo, podem ajudar a corroborar hipóteses levantadas por quem está realizando a análise.
                                     
O iremos aplicar os métodos de Chow^[G. C. Chow. Tests of equality between sets of coefficients in two linear regressions. Econometrica,28:591–605, 1960], Zeileis^[A. Zeileis, F. Leisch, K. Hornik, and C. Kleiber. strucchange: An R package for testing for structural change in linear regression models. Journal of Statistical Software, 7(2):1–38, 2002.doi: 10.18637/jss.v007.i02] e Brown^[R. L. Brown, J. Durbin, and J. M. Evans. Techniques for testing the constancy of regression relationships over time. Journal of the Royal Statistical Society B, 37:149–163, 1975.]. Todos os testes estão implementados na biblioteca **strucchange** do **R**^[https://cran.r-project.org/web/packages/strucchangeRcpp/vignettes/strucchange-intro.pdf].

O teste aplicado verifica se a média das séries mudou ao longo do tempo. Caso tenha mudado, este é também um indício de que a série não é estacionária. 

As propriedades estatísticas de uma série temporal estacionária são constantes ao longo do tempo, como a média, a variância e a auto correlação.
             
:::

### Série de valor exportado em US$ 
                                  
::: {style="text-align: justify"}
                                     
Os resultados dos testes abaixo **são** estatisticamente significativos e mostram que existe uma quebra estrutural na série de valor exportado em **2015**.
                                     
```{r}
#| echo: false
#| message: false
#| warning: false
#| label: build_ts_val

# converte os dados para série temporal
ts_val <- ts(
  data_exp_mc_by_date_clean |>
    dplyr::select(sum_val_clean),
  frequency = 12,
  start = c(2000,01,01),
  end = c(2022,12,01)
)
```
 
 
 
O modelo de quebra estrutural baseado em minimos quadrados e na soma acumulada (OLS/CUSUM) permite a divisão da série em dois segmentos, ou seja, permite que seja identificada uma quebra estrutural. 

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-efp_ts_val
#| fig-cap: "Teste de flutuação empírica para quebras estruturais - valor total exportado em US$."

ocus <- efp(ts_val ~ 1, data = ts_val, type="OLS-CUSUM")
bound.ocus <- boundary(ocus, alpha=0.05)
bp.ts_val_ocus <- breakpoints(Fstats(ts_val~1))


plot(ocus, boundary = FALSE)
lines(bound.ocus, col = 4)
lines(-bound.ocus, col = 4)
lines(bp.ts_val_ocus)

```

O teste OLS/CUSUM mostra que o pico em que o processo ultrapassou a banda superior em março de 2015. Neste período existe evidência de que tenha ocorrido uma quebra estrutural (@fig-efp_ts_val).

Ainda, o teste de Chow mostra que a quebra estrutural é estatisticamente significativa, pois o valor de F é muito maior que 1, e o p-valor é menor que 0,05, indicando assim que a $H_0$ de inexistência de quebra estrutural pode ser rejeitada[^https://www.jstatsoft.org/article/view/v007i02].
                                     
```{r}
#| echo: false
#| message: false
#| warning: false
#| label: summ_breakpoints_ts_val
sctest(ts_val~1, type = "Chow")
```    

Podemos então partir para um outro modelo em que permitimos a ocorrência de mais de uma quebra estrutural, o qual é baseado na estística F (*F Statistics*). 
                                                                       
                                     
```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-chow_ts_val
#| fig-cap: "Estatísticas do teste de quebras estruturais - valor total exportado em US$."
#| layout-ncol: 3 

fs <- Fstats(ts_val ~ 1)
bp.ts_val <- breakpoints(ts_val ~ 1)



#par(mfrow = c(1, 3))
plot(fs, xlab = "Ano")
plot(fs,
     pval = TRUE,
     xlab = "Ano")
plot(bp.ts_val, xlab="Número de pontos de quebra")
```
Como podemos ver na @fig-chow_ts_val-3, o modelo nos sugere a existência de três pontos de quebra (valor mais baixo de BIC), com as quebras estruturais podendo ser identificadas na @fig-breakpoints_ts_val em: abril de 2005, setembro de  2008 e agosto de 2014.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-breakpoints_ts_val
#| fig-cap: "Identificação gráfica de quebras estruturais - valor total exportado em US$."

plot(fs)
lines(bp.ts_val)
```
:::

### Série de volume exportado em L (1L = 1kg) 

::: {style="text-align: justify"}


Os testes de quebra estrutural identificaram inicialmente a existência de uma quebra em julho de 2003. Mas podemos observar que o pico não ultrapassa significativamente a banda superior. 

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: build_ts_vol

# converte os dados para série temporal
ts_vol <- ts(data_exp_mc_by_date_clean |> 
dplyr::select(sum_vol_clean),
frequency = 12, 
start = c(2000,01,01), 
end = c(2022,12,01)
)
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-efp_ts_vol
#| fig-cap: "Teste de flutuação empírica para quebras estruturais - volume total exportado em L."

ocus <- efp(ts_vol ~ 1, data = ts_vol, type="OLS-CUSUM")
bound.ocus <- boundary(ocus, alpha=0.05)
bp.ts_vol_ocus <- breakpoints(Fstats(ts_vol~1))


plot(ocus, boundary = FALSE)
lines(bound.ocus, col = 4)
lines(-bound.ocus, col = 4)
lines(bp.ts_vol_ocus)
```
O teste de Chow, por seu turno, indica que a quebra identificada não é estatisticamente significativa. O valor de F é maior que 1, porém o p-valor permite rejeitar a $H_0$ de existência de quebras estruturais ao nível de 5% de significância.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: summ_breakpoints_ts_vol
sctest(ts_vol ~ 1, type = "Chow")
```

Em contrapartida, utilizando o modelo que permite mais de dois segmentos de reta na série, foi identificada existência de três quebras estruturais: julho de 2003, abril de 2012 e setembro de 2015.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-chow_ts_vol
#| fig-cap: "Estatísticas do teste de quebras estruturais - volume total exportado em L."
#| layout-ncol: 3 

fs <- Fstats(ts_vol ~ 1)
bp.ts_vol <- breakpoints(ts_vol ~ 1)



plot(fs, xlab = "Ano")
plot(fs,
     pval = TRUE,
     xlab = "Ano")
plot(bp.ts_vol, xlab="Número de pontos de quebra")


```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-breakpoints_ts_vol
#| fig-cap: "Identificação gráfica de quebras estruturais - volume total exportado em L."


plot(fs)
lines(bp.ts_vol)

```


:::

::: {.callout-note}
É importante notar que os testes ademais de apontarem para a existência de fatores externos que alteraram a trajetória das séries, reforçam a hipótese de que as séries não são estacionárias, o que pode ser decorrente do efeito das componentes de tendência e sazonalidade. Vale ainda ressaltar que, mesmo tendo sido retiradas da série as anomalias, isto não foi suficiente para fazer com que a série se tornasse estacionária.
:::

::: {.callout-caution}
Quando a série não é estacionária, não é recomendável realizar qualquer análise de correlação com outras séries sem que haja o devido tratamento da série e/ou o uso de métodos mais robustos de análise, visto que a existência de raizes unitárias (causadas por quebras estruturais, por exemplo) favorece a ocorrência das chamadas correlações espúrias. Existem vários exemplos de tais correlações que podem ser visualizados na página [Spurious Correlations](http://www.tylervigen.com/spurious-correlations).
:::

###  Modelos preditivos



#### Modelos ARIMA

::: {style="text-align: justify"}
Os testes das seções anteriores indicam que as séries não são estacionárias. Logo, o uso de modelos de previsão univariados do tipo $ARIMA$ ou $SARIMA$ (para os casos em que há sazonalidade) podem ser adequados para a a modelagem das séries em questão, desde que se proceda com a transformação das séries, seja por meio da aplicação de $log$, seja pela diferenciação da série.

Para a construção do primeiro modelo preditivo, utilizaremos o algoritmo desenvolvido por Rob J. Hyndman e Yeasmin Khandakar^[https://www.jstatsoft.org/article/view/v027i03] e implementado em **R** na biblioteca **forecast**. O algoritmo define automaticamente os parâmetros do modelo ARIMA de modo que os resíduos sejam independentes. Portanto: 

$$
\begin{align}
ARIMA(p,d,q)(P,D,Q)_m \\ 
\textrm{tal que:}\\ \textrm{p-ordem do modelo autorregressivo}\\ \textrm{d-ordem de diferenciação}\\ \textrm{q-ordem da média-móvel}\\ \textrm{P, D, Q- parte sazonal do modelo}\\ \textrm{m-número de observações por ano}
\end{align}
$$

A parte sazonal do modelo consiste em termos que são similares às componentes não-sazonais do modelo, mas envolvem a defasagem do período sazonal.

O processo de construção de modelos preditivos pode inclusive auxiliar na melhor compreensão do processo gerador de dados das séries. Contudo, não será realizada uma discussão aprofundada sobre os modelos, uma vez que está fora do escopo deste trabalho.

Para a série de valor exportado, o modelo selecionado pelo algoritmo é o $ARIMA(0,1,1)(0,0,1)_{12}$, ou seja, é integrado de ordem 1 ($p = 1$), média-móvel com $q=1$ e com compo, corroborando a hipótese de que a série é não estacionária. 

Quanto à série de volume exportado, o modelo ajustado foi o $ARIMA(2,0,2)(2,0,0)_{12}$. Neste caso, o algoritmo não indicou a diferenciação da série, mas além de ter identificado a componente sazonal com ordem 2, é também um modelo autorregressivo e média-móvel de ordem 2.

:::
```{r}
#| echo: false
#| message: false
#| warning: false
#| cache: true
#| label: fig-arima-model-ts_val
#| fig-cap: 
#|  -"Modelo auto-arima para o valor total exportado em US$"
#|  -"Modelo auto-arima para o volume total exportado em Kg.L" 
#| layout-nrow: 2


ts_val <- ts(data_exp_mc_by_date_clean |> 
dplyr::select(sum_val_clean),
frequency = 12, 
start = c(2000,01,01), 
end = c(2022,12,01)
)

ts_vol <- ts(data_exp_mc_by_date_clean |> 
dplyr::select(sum_vol_clean),
frequency = 12, 
start = c(2000,01,01), 
end = c(2022,12,01)
)


fit_ts_val <- forecast::auto.arima(ts_val)
forecast::checkresiduals(fit_ts_val)

fit_ts_vol <- forecast::auto.arima(ts_vol)
forecast::checkresiduals(fit_ts_vol)

```
 
#### Outros modelos

::: {style="text-align: justify"}

 A seguir, para enriquecermos a análise e passarmos para a elaboração de previsões sobre o mercado de exportação de vinhos brasileiros, vamos construir dois outros modelos da biblioteca biblioteca [modeltime](https://business-science.github.io/modeltime/):
 - Arima boost (auto-arima XGBoost), e
 - PROPHET model.

```{r}
#| echo: false
#| message: false
#| warning: false

library(xgboost)
library(tidymodels)
library(modeltime)
library(tidyverse)
library(timetk)

ts_val <- data_exp_mc_by_date_clean |>
                               select(c('date','sum_val_clean')) |>
                               arrange(date)
ts_vol <- data_exp_mc_by_date_clean |>
                               select(c('date','sum_vol_clean')) |>
                               arrange(date)

splits_val <- initial_time_split(ts_val, prop = 0.9)
splits_vol <- initial_time_split(ts_vol, prop = 0.9)
# 
# # Model 1: auto_arima ----
# model_fit_arima_no_boost <- arima_reg()  |> 
#     set_engine(engine = "auto_arima") |> 
#     fit(sum_val_clean ~ date, data = training(splits))

```


```{r}
#| echo: false
#| message: false
#| warning: false
#| cache: true

# Model 2: arima_boost ----
model_fit_arima_boosted_val <- arima_boost(
    min_n = 2,
    learn_rate = 0.025
) |> 
    set_engine(engine = "auto_arima_xgboost") %>%
    fit(sum_val_clean ~ date + as.numeric(date) + factor(month(date, label = TRUE), ordered = F),
        data = training(splits_val))


model_fit_arima_boosted_vol <- arima_boost(
    min_n = 2,
    learn_rate = 0.02,
    non_seasonal_ma = 2
) |> 
    set_engine(engine = "auto_arima_xgboost") %>%
    fit(sum_vol_clean ~ date + as.numeric(date) + factor(month(date, label = TRUE), ordered = F),
        data = training(splits_vol))


```


```{r}
#| echo: false
#| message: false
#| warning: false
#| cache: true

# Model 4: prophet ----
model_fit_prophet_val <- prophet_reg() %>%
    set_engine(engine = "prophet") %>%
    fit(sum_val_clean ~ date, data = training(splits_val))


model_fit_prophet_vol <- prophet_reg() %>%
    set_engine(engine = "prophet") %>%
    fit(sum_vol_clean ~ date, data = training(splits_vol))


```

Para a série de valor exportado, seguem os detalhes dos modelos calculados:  

:::{#tbl-models-val}
```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-models-val
#| cache: true

models_tbl_val <- modeltime_table(
    model_fit_arima_boosted_val,
    model_fit_prophet_val
)

calibration_tbl_val <- models_tbl_val %>%
    modeltime_calibrate(new_data = testing(splits_val))





 models_tbl_val$.model[1]

 models_tbl_val$.model[2]



```
Modelos para a série de valor exportado.
:::
Para a série de volume exportado, seguem os detalhes dos modelos calculados:  

:::{#tbl-models-vol}
```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-models-vol
#| cache: true

models_tbl_vol <- modeltime_table(
    model_fit_arima_boosted_vol,
    model_fit_prophet_vol
)

calibration_tbl_vol <- models_tbl_vol %>%
    modeltime_calibrate(new_data = testing(splits_vol))



models_tbl_vol$.model[1]
models_tbl_vol$.model[2]
```
Modelos para a série de volume exportado.

:::

```{r}
#| cache: true
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Série temporal de valor exportado observada e previsões por meio dos modelos ARIMA e PROPHET"
#| label: fig-calibration_tbl_val
  
calibration_tbl_val %>%
    modeltime_forecast(
        new_data    = testing(splits_val),
        actual_data = ts_val
    ) %>%
    plot_modeltime_forecast(
      .legend_max_width = 25, # For mobile screens
      .interactive      = TRUE
    )
```

```{r}
#| cache: true
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Série temporal de volume exportado observada e previsões por meio dos modelos ARIMA e PROPHET"
#| label: fig-calibration_tbl_vol
  
calibration_tbl_vol %>%
    modeltime_forecast(
        new_data    = testing(splits_vol),
        actual_data = ts_vol
    ) %>%
    plot_modeltime_forecast(
      .legend_max_width = 25, # For mobile screens
      .interactive      = TRUE
    )
```


::: {#tbl-calibration_tbl_val}
```{r}
#| cache: true
#| echo: false
#| message: false
#| warning: false
#| label: tbl-calibration_tbl_val
#| tbl-cap: "Métricas de acurácia - valor exportado"

calibration_tbl_val %>%
    modeltime_accuracy() %>%
    table_modeltime_accuracy(
        .interactive = TRUE
    )
```
Métricas de acurácia - valor exportado
:::

As métricas da @tbl-calibration_tbl_val mostram que o modelo que apresentou o melhor ajuste foi o modelo PROPHET, com os menores erros quando comparado ao modelo ARIMA.


::: {#tbl-calibration_tbl_vol}
```{r}
#| cache: true
#| echo: false
#| message: false
#| warning: false
#| label: tbl-calibration_tbl_vol
#| tbl-cap: "Métricas de acurácia - volume exportado"

calibration_tbl_vol %>%
    modeltime_accuracy() %>%
    table_modeltime_accuracy(
        .interactive = TRUE
    )
```
Métricas de acurácia - volume exportado
:::

As métricas da @tbl-calibration_tbl_vol,por outro lado, mostram que o modelo ARIMA foi aquele que apresentou o melhor ajuste.

A seguir temos a @fig-refit_tbl_val e @fig-refit_tbl_vol, pós refit, com a previsão para as séries até dezembro 2025. Em ambos os casos é interessante notarmos que os modelos indicam certa queda no valor e no volume exportados. É evidente que uma análise mais aprofundada, inclusive multivariada, poderia trazer resultados diferentes e até mais interessantes. Porém isto está fora do escopo deste trabalho. 

```{r}
#| cache: true
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Refit da série original e previsão para três anos - valor exportado"
#| label: fig-refit_tbl_val

refit_tbl_val <- calibration_tbl_val %>%
    modeltime_refit(data = ts_val)

refit_tbl_val %>%
    modeltime_forecast(h = "3 years", actual_data = ts_val) %>%
    plot_modeltime_forecast(
      .legend_max_width = 15, # For mobile screens
      .interactive      = TRUE
    )

```

```{r}
#| cache: true
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Refit da série original e previsão para três anos - volume exportado"
#| label: fig-refit_tbl_vol

refit_tbl_vol <- calibration_tbl_vol %>%
    modeltime_refit(data = ts_vol)

refit_tbl_vol %>%
    modeltime_forecast(h = "3 years", actual_data = ts_vol) %>%
    plot_modeltime_forecast(
      .legend_max_width = 12, # For mobile screens
      .interactive      = TRUE
    )

```



:::
